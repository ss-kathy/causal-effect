---
title: "data simulation1"
author: "ss5929"
date: "7/30/2020"
output: pdf_document
  
---

```{r,include=FALSE,warning=FALSE,message=FALSE,results='hide'}
library(tidyverse)
library(tseries)
library(changepoint)
library(kableExtra)

```

## Exposure
For the exposure, in this scenario, I will only use $x_{t(j)}$ and $x_{t(j-1)}$ to predict $x_{t(j+1)}$ and then the data generation process(DGP) is:

$$
x_{t(j+1)} = g^X(x_{t(j)},x_{t(j-1)})
$$

for each time point, $x_{t(j)}$ will follow a Bernoulli distribution and the data generation model is(DGM):

$$
X_{t(j+1)} \sim bernoulli(logit(p_{t(j+1)}))
$$
$$
logit(p_{t(j+1)}) = \nu_t + \phi_{1,t}X_{t(j)} + \phi_{2,t}X_{t(j-1)}
$$
Here, $\nu_t$ means fixed effect for x at different time periods which is decided by the probability of having high count/texts in each time period. To make it stationary and close to the fact the first lag will have more effect to the current day than the second lag, $\phi_1$ and $\phi_2$ are restricted as:

$$
\begin{aligned}
|\phi_1+\phi_2|<1\\
|\phi_2-\phi_1|<1\\
|\phi_1|<1\\
|\phi_2|<1\\
|\phi_2|<|\phi_1|
\end{aligned}
$$

```{r,warning=FALSE}
#x = c(rbinom(500,1,6/7),rbinom(800,1,2/7),rbinom(400,1,5/7),rbinom(600,1,3/7),rbinom(700,1,1/7))
seed = 1234
# simulate x
x = NULL
phi1 = c(1/7,1/20,1/8,1/10,1/30) # set up phi1
phi2 = c(1/8,1/30,1/9,1/12,1/40) # set up phi2
gama = c(1,-0.9,0.9,-0.3,-1.8) # define gama(fixed value)
num = c(500,800,400,600,700)  # define the number of time points in every period
x_test_result = NULL


id = 0
for(j in 1:5)
{
  set.seed(3399)
  p.treat = NULL
  p = NULL
  a = NULL
  a[1] = ifelse(j==1,1,ifelse(j==2,0,ifelse(j==3,0,ifelse(j==4,1,ifelse(j==5,0,NULL))))) 
  a[2] = ifelse(j==1,1,ifelse(j==2,0,ifelse(j==3,1,ifelse(j==4,0,ifelse(j==5,0,NULL))))) # set up the first and second value in each period
  for(i in 3:num[j])
  {
    p[i] = gama[j]+phi1[j]*a[i-1]+phi2[j]*a[i-2]+eta[id:(id+num[j])][i]*u[id:(id+num[j])][i]
    p.treat= exp(p[i])/(1+exp(p[i]))
    a[i] =sample(rbinom(1000,1,p.treat),size=1)

  }
  adf = adf.test(a)
  x_test_result[j] = adf$p.value
  x=c(x,a)
  id = id+num[j]

}

plot(cpt.mean(x,penalty='Manual',pen.value = 2,method='PELT')) 

mean_x = NULL
variance_x = NULL
idx = 0
for(i in 1:5)
{
  mean_x[i] = mean(x[idx:(idx+num[i])])
  variance_x[i] = var(x[idx:(idx+num[i])])
  idx = idx+num[i]
}

```

The parameters for the exposure are shown as below:
```{r, echo = F}
tibble(
  time.period = c(1,2,3,4,5),
  num,
  gama,
  probability = c(6/7,2/7,5/7,3/7,1/7),
) %>% 
  kable(.,align = 'c',booktabs=T) %>% 
  add_header_above(c(" "=2, "Parameters of Exposure" = 2))

```



## Outcome without confounder
The DGP is:
$$
Y_{t(j)} = g^Y(X_{t(j)},Y_{t(j-1)},U_{t(j)})
$$

The DGM is:
$$
Y_{t(j)} = \zeta_t + \alpha_t X_{t(j)} + \phi_t Y_{t(j-1)} + \eta_{t(j)} U_{t(j)} +\varepsilon_{t(j)}
$$

$\zeta_t$: fixed effect for Y at different time period

$U_{t(j)}$: other nonexposure covariates

$\varepsilon_{t(j+1)} ~ N(0,\sigma_t^2)$: error term\

Other covariates and $\eta_{t(j)}$ will be updated evey time when a new observation is added:

$U_{t(j+1)} = U_t^\triangle + \rho_{1,t}(U_{t(j)}-U_t^\triangle) + w_{1,t(j)}$ $w_{1,t(j)} \sim N(0,\sigma_{1,w}^2)$

$\eta_{t(j+1)} = \eta_t^\triangle + \rho_{2,t}(\eta_{t(j)}-\eta_t^\triangle) + w_{2,t(j)}$ $w_{1,t(j)} \sim N(0,\sigma_{2,w}^2)$

```{r,warning=FALSE}
# simulate nonexposure covariates U
u = NULL
var_u = 0.08
u0 = c(2.5,1.8,2.3,1.5,1)/2
rho1 = c(0.3,0.2,0.3,0.2,0.1)/2
first_u = c(0.7,1.2,1.8,0.8,0.5)
test_result_u = NULL

# simulate eta
eta = NULL
var_eta = 0.08
eta0 = c(2.2,1.6,2,1.4,1)/2
rho2 = c(0.2,0.1,0.2,0.14,0.08)/2
first_eta = c(1.25,1.05,1.15,0.95,0.55)
test_result_eta = NULL

# simulate alphap
alphap = NULL
var_alphap = 0.05
alphap0 = c(3.2,1.8,2.6,1.6,1.2)/2
rho3 = c(0.2,0.1,0.2,0.14,0.08)
first_alphap = c(2,1.7,1.5,1.4,1)
test_result_alphap = NULL


for(j in 1:5)
{
  set.seed(seed)
  c=NULL
  d=NULL
  b=NULL
  c[1] = first_u[j]
  d[1] = first_eta[j] 
  b[1] = first_alphap[j]
  error_u = rnorm(num[j],0,sqrt(var_u))
  error_eta = rnorm(num[j],0,sqrt(var_eta))
  error_alphap = rnorm(num[j],0,sqrt(var_alphap))
  for(i in 2:num[j])
  {
    c[i] = u0[j] + rho1*(c[i-1]-u0[j])+error_u[i]
    d[i] = eta0[j] + rho2*(d[i-1]-eta0[j])+error_eta[i]
    b[i] = alphap0[j] + rho3*(d[i-1]-alphap0[j])+error_alphap[i]
  }
  adf_u = adf.test(c)
  adf_eta = adf.test(d)
  adf_alphap = adf.test(b)
  test_result_u[j] = adf_u$p.value
  test_result_eta[j] = adf_eta$p.value
  test_result_alphap[j] = adf_alphap$p.value
  u = c(u,c)
  eta = c(eta,d)
  alphap = c(alphap,b)
  error_u = NULL
  error_eta = NULL
  error_alphap = NULL
  
}


plot(cpt.mean(u,penalty='Manual',pen.value = 2,method='PELT')) 
plot(cpt.mean(eta,penalty='Manual',pen.value = 2,method='PELT'))
plot(cpt.mean(alphap,penalty='Manual',pen.value = 2,method='PELT')) 


```


```{r,warning=FALSE}
#simulate Y
test_result_y=NULL
test_result_y2 =NULL
test_result_y3=NULL
var_y = 0.0001
var_y2 = 0.00001
var_y3 = 0.0001
y=NULL
y2=NULL
y3=NULL
first_y = c(3.3,2.3,3,2.6,2)
first_y2 = c(3.3,2.3,3,2.6,2)
first_y3 = c(3.6,2.3,3.3,2.6,2)


zeta = c(2,1,2,1.5,0.8)/10 #fixed effect for y at different time period
phi = c(0.8,0.5,0.7,0.6,0.4)/15
alpha = c(2.4,2,2.3,2.2,1.8)/2
beta1 = c(1.2,0.7,1.1,0.9,0.6)/2

id=0
for(j in 1:5)
{
  set.seed(seed)
  e =NULL
  e2=NULL
  e3 = NULL
  e[1] = first_y[j]
  e2[1] = first_y2[j]
  e3[1] = first_y3[j]
  error_y = rnorm(num[j],0,sqrt(var_y))
  error_y2 = rnorm(num[j],0,sqrt(var_y2))
  error_y3 = rnorm(num[j],0,sqrt(var_y3))
  for(i in 2:num[j])
  {
    set.seed(seed)
    e[i] = zeta[j]+alpha[j]*x[id:(id+num[j])][i]+phi[j]*e[i-1]+
      eta[id:(id+num[j])][i]*u[id:(id+num[j])][i]+error_y[i]
    
    e2[i] = zeta[j]+alpha[j]*x[id:(id+num[j])][i]+phi[j]*e[i-1]+
      eta[id:(id+num[j])][i]*u[id:(id+num[j])][i]+error_y2[i]+beta1[j]*x[id:(id+num[j])][i-1]
    
    e3[i] = zeta[j]+alphap[id:(id+num[j])][i]*x[id:(id+num[j])][i]+phi[j]*e[i-1]+
      eta[id:(id+num[j])][i]*u[id:(id+num[j])][i]+error_y3[i]
  }
  adf = adf.test(e)
  adf2 = adf.test(e2)
  adf3 = adf.test(e3)
  test_result_y[j] = adf$p.value
  test_result_y2[j] = adf2$p.value
  test_result_y3[j] = adf3$p.value
  y = c(y,e) 
  y2 = c(y2,e2) # with confounder
  y3 = c(y3,e3) # with different alpha at each time point
  error_y =NULL
  error_y2 = NULL
  error_y3 = NULL
  id=id+num[j]
}

plot(as.ts(y))
plot(cpt.mean(y,penalty='Manual',pen.value = 12,method='PELT')) 

plot(as.ts(y2))
plot(cpt.mean(y2,penalty='Manual',pen.value = 12,method='PELT'))

plot(as.ts(y3))
plot(cpt.mean(y3,penalty='Manual',pen.value = 12,method='PELT'))

```


Parameters for the outcome are shown as below:
```{r,echo =FALSE,warning=F}
tibble(
  time.period = c(1,2,3,4,5),
  num,
  var_u = rep(var_u,5),
  u0,
  rho1,
  var_eta = rep(var_eta,5),
  eta0,
  rho2,
  alpha,
  zeta,
  phi
) %>%round(.,digits = 2) %>% 
  kable(.,align = 'c',booktabs=T) %>% 
  add_header_above(c(" "=2, "other covariates" = 3, "eta" = 3,
                     "final outcome" = 3)) 
  


```


# outcome with confounder

The data generation process(DGP) will be:

$$
Y_{t(j)} = g^Y(X_{t(j)},X_{t(j-1)},Y_{t(j-1)},U_{t(j)})
$$
The data generation model(DGM) will be:
$$
Y_{t(j)} = \zeta_t + \alpha_t X_{t(j)}+\beta_{1,t}X_{t(j-1)}+\phi_t Y_{t(j-1)}+ \eta_{t(j)} U_{t(j)} +\varepsilon_{t(j)}
$$


# distributions
```{r,echo = F,warning=F}
mean_u = NULL
variance_u = NULL
truevar_u = NULL
truemean_u = NULL
idx = 0
for(i in 1:5)
{
  mean_u[i] = mean(u[idx:(idx+num[i])])
  variance_u[i] = var(u[idx:(idx+num[i])])
  idx = idx+num[i]
  truevar_u[i]  = (var_u/(1-rho1[i]^2))
  truemean_u[i] = (1-rho1[i])*u0[i]
}

mean_eta = NULL
variance_eta = NULL
truemean_eta = NULL
truevar_eta = NULL
idx = 0
for(i in 1:5)
{
  mean_eta[i] = mean(eta[idx:(idx+num[i])])
  variance_eta[i] = var(eta[idx:(idx+num[i])])
  idx = idx+num[i]
  truevar_eta[i]  = (var_eta/(1-rho2[i]^2))
  truemean_eta[i] = (1-rho2[i])*eta0[i]
}

mean_y = NULL
variance_y = NULL
idx = 0
for(i in 1:5)
{
  mean_y[i] = mean(y[idx:(idx+num[i])])
  variance_y[i] = var(y[idx:(idx+num[i])])
  idx = idx+num[i]
}

mean_y2 = NULL
variance_y2 = NULL
idx = 0
for(i in 1:5)
{
  mean_y2[i] = mean(y2[idx:(idx+num[i])])
  variance_y2[i] = var(y2[idx:(idx+num[i])])
  idx = idx+num[i]
}


tibble(
  time_period = c(1,2,3,4,5),
  mean_x,
  variance_x,
  mean_y,
  variance_y,
  mean_y2,
  variance_y2
) %>%round(.,digits = 2) %>% 
  kable(.,align = 'c',booktabs=T) %>% 
  add_header_above(c(" "=1, "exposure" = 2, "outcome without condounder" = 2,"outcome with confounder" =2)) 

tibble(
  time_period = c(1,2,3,4,5),
  mean_u,
  variance_u,
  truemean_u,
  truevar_u
)%>%
  kable(.,align = 'c',booktabs=T) %>% 
  add_header_above(c(" "=1, "other covariates" = 4)) 
  
tibble(
  time_period = c(1,2,3,4,5),
  mean_eta,
  variance_eta,
  truemean_eta,
  truevar_eta
)%>%
  kable(.,align = 'c',booktabs=T) %>% 
  add_header_above(c(" "=1, "parameter of other covariates" = 4)) 



```


```{r}
# generate final data frame
final1 = as.data.frame(cbind(x,y,u,y2,y3,alphap))
write.csv(final1,file = "final1.csv")

```








